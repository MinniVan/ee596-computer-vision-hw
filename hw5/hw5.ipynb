{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_rule():\n",
    "    \"\"\"\n",
    "    Compute df/dz, df/dq, df/dx, and df/dy for f(x,y,z)=xy+z,\n",
    "    where q=xy, at x=-2, y=5, z=-4.\n",
    "    Return them in this order: df/dz, df/dq, df/dx, df/dy. \n",
    "    \"\"\"\n",
    "    x, y, z = -2.0, 5.0, -4.0\n",
    "    \n",
    "    df_dz = 1.0\n",
    "    df_dq = 1.0\n",
    "    df_dx = df_dq * y\n",
    "    df_dy = df_dq * x\n",
    "\n",
    "    return df_dz, df_dq, df_dx, df_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 5.0, -2.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_rule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU():\n",
    "    \"\"\"\n",
    "    Compute dx and dw, and return them in order.\n",
    "    Forward:\n",
    "        y = ReLU(w0 * x0 + w1 * x1 + w2)\n",
    "\n",
    "    Returns:\n",
    "        dx -- gradient with respect to input x, as a vector [dx0, dx1]\n",
    "        dw -- gradient with respect to weights (including the third term w2), \n",
    "              as a vector [dw0, dw1, dw2]\n",
    "    \"\"\"\n",
    "    x = [-1.0, -2.0]\n",
    "    w = [2.0, -3.0, -3.0]\n",
    "    z = w[0]*x[0] + w[1]*x[1] + w[2]\n",
    "    y = max(0.0, z)     # ReLU function\n",
    "    dy_dz = 1.0 if z > 0 else 0.0\n",
    "    dx = [dy_dz*w[0], dy_dz*w[1]]\n",
    "    dw = [dy_dz*x[0], dy_dz*x[1], dy_dz*1]\n",
    "    return dx, dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.0, -3.0], [-1.0, -2.0, 1.0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_rule_a():\n",
    "    \"\"\"\n",
    "    In the lecture notes, the last three forward pass values are \n",
    "    a=0.37, b=1.37, and c=0.73.  \n",
    "    Calculate these numbers to 4 decimal digits and return in order of a, b, c\n",
    "    \"\"\"\n",
    "    # inputs + weights from lecture\n",
    "    x0 = torch.tensor(-1.00)\n",
    "    x1 = torch.tensor(-2.00)\n",
    "    w0 = torch.tensor(2.00, requires_grad=True)\n",
    "    w1 = torch.tensor(-3.00, requires_grad=True)\n",
    "    w2 = torch.tensor(-3.00, requires_grad=True)\n",
    "\n",
    "    # Forward pass\n",
    "    z = w0*x0 + w1*x1 + w2\n",
    "    a = torch.exp(-z)\n",
    "    b = 1 + torch.exp(-z)       # sigmoid denominator\n",
    "    c = 1 / b                   # sigmoid output\n",
    "    return round(a.item(), 4), round(b.item(), 4), round(c.item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3679, 1.3679, 0.7311)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_rule_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_rule_b():\n",
    "    \"\"\"\n",
    "    In the lecture notes, the backward pass values are\n",
    "    ±0.20, ±0.39, -0.59, and -0.53.  \n",
    "    Calculate these numbers to 4 decimal digits \n",
    "    and return in order of gradients for w0, x0, w1, x1, w2.\n",
    "    \"\"\"\n",
    "    x0 = torch.tensor(-1.0, requires_grad=True)\n",
    "    x1 = torch.tensor(-2.0, requires_grad=True)\n",
    "    w0 = torch.tensor(2.0, requires_grad=True)\n",
    "    w1 = torch.tensor(-3.0, requires_grad=True)\n",
    "    w2 = torch.tensor(-3.0, requires_grad=True)\n",
    "\n",
    "    # forward pass\n",
    "    z = w0 * x0 + w1 * x1 + w2\n",
    "    y = 1 / (1 + torch.exp(-z))  # sigmoid\n",
    "\n",
    "    # backward pass\n",
    "    y.backward()\n",
    "\n",
    "    return (\n",
    "        round(w0.grad.item(), 4),\n",
    "        round(x0.grad.item(), 4),\n",
    "        round(w1.grad.item(), 4),\n",
    "        round(x1.grad.item(), 4),\n",
    "        round(w2.grad.item(), 4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.1966, 0.3932, -0.3932, -0.5898, 0.1966)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_rule_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_a():\n",
    "    \"\"\"\n",
    "    Let f(w,x) = torch.tanh(w0x0+w1x1+w2).  \n",
    "    Assume the weight vector is w = [w0=5, w1=2], \n",
    "    the input vector is  x = [x0=-1,x1= 4],, and the bias is  w2  =-2.\n",
    "    Use PyTorch to calculate the forward pass of the network, return y_hat = f(w,x).\n",
    "    \"\"\"\n",
    "    x0 = torch.tensor(-1.0)\n",
    "    x1 = torch.tensor(4.0)\n",
    "    \n",
    "    w0 = torch.tensor(5.0, requires_grad=True)\n",
    "    w1 = torch.tensor(2.0, requires_grad=True)\n",
    "    w2 = torch.tensor(-2.0, requires_grad=True)\n",
    "\n",
    "    z = w0 * x0 + w1 * x1 + w2\n",
    "    y_hat = torch.tanh(z)  \n",
    "\n",
    "    return round(y_hat.item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_b():\n",
    "    \"\"\"\n",
    "    Use PyTorch Autograd to calculate the gradients \n",
    "    for each of the weights, and return the gradient of them \n",
    "    in order of w0, w1, and w2.\n",
    "    \"\"\"\n",
    "    x0 = torch.tensor(-1.0, requires_grad=True)\n",
    "    x1 = torch.tensor(4.0, requires_grad=True)\n",
    "\n",
    "    w0 = torch.tensor(5.0, requires_grad=True)\n",
    "    w1 = torch.tensor(2.0, requires_grad=True)\n",
    "    w2 = torch.tensor(-2.0, requires_grad=True)\n",
    "\n",
    "    # forward\n",
    "    z = w0 * x0 + w1 * x1 + w2\n",
    "    y_hat = torch.tanh(z)\n",
    "\n",
    "    target = torch.tensor(1.0)\n",
    "    loss = (y_hat - target) ** 2    # MSE for single sample\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    gw0 = round(w0.grad.item(), 4)\n",
    "    gw1 = round(w1.grad.item(), 4)\n",
    "    gw2 = round(w2.grad.item(), 4)\n",
    "\n",
    "    return gw0, gw1, gw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_c():\n",
    "    \"\"\"\n",
    "    Assuming a learning rate of 0.1, \n",
    "    update each of the weights accordingly. \n",
    "    For simplicity, just do one iteration. \n",
    "    And return the updated weights in the order of w0, w1, and w2 \n",
    "    \"\"\"\n",
    "    x0 = torch.tensor(-1.0, requires_grad=True)\n",
    "    x1 = torch.tensor(4.0, requires_grad=True)\n",
    "\n",
    "    w0 = torch.tensor(5.0, requires_grad=True)\n",
    "    w1 = torch.tensor(2.0, requires_grad=True)\n",
    "    w2 = torch.tensor(-2.0, requires_grad=True)\n",
    "\n",
    "    # forward\n",
    "    z = w0 * x0 + w1 * x1 + w2\n",
    "    y_hat = torch.tanh(z)\n",
    "    target = torch.tensor(1.0)\n",
    "    loss = (y_hat - target) ** 2\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    lr = 0.1\n",
    "    w0_updated = w0 - lr * w0.grad\n",
    "    w1_updated = w1 - lr * w1.grad\n",
    "    w2_updated = w2 - lr * w2.grad\n",
    "\n",
    "    return (round(w0_updated.item(), 4),\n",
    "            round(w1_updated.item(), 4),\n",
    "            round(w2_updated.item(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructParaboloid(w=256, h=256):\n",
    "    img = np.zeros((w, h), np.float32)\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            # let's center the paraboloid in the img\n",
    "            img[y, x] = (x - w / 2) ** 2 + (y - h / 2) ** 2\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for getting dervitatives\n",
    "def _compute_derivatives(paraboloid_4d: torch.Tensor):\n",
    "    \"\"\"\n",
    "    paraboloid_4d: (1,1,H,W)\n",
    "    return: gx, gy, gxx, gyy  all (1,1,H,W),\n",
    "    \"\"\"\n",
    "    # sobel-like for 1st order\n",
    "    kx = torch.tensor(\n",
    "        [[[[-1., 0., 1.],\n",
    "           [-2., 0., 2.],\n",
    "           [-1., 0., 1.]]]], dtype=torch.float32)\n",
    "    ky = torch.tensor(\n",
    "        [[[[-1., -2., -1.],\n",
    "           [ 0.,  0.,  0.],\n",
    "           [ 1.,  2.,  1.]]]], dtype=torch.float32)\n",
    "\n",
    "    # simple 2nd-derivative kernels\n",
    "    kxx = torch.tensor(\n",
    "        [[[[1., -2., 1.],\n",
    "           [1., -2., 1.],\n",
    "           [1., -2., 1.]]]], dtype=torch.float32)\n",
    "    kyy = torch.tensor(\n",
    "        [[[[1.,  1.,  1.],\n",
    "           [-2., -2., -2.],\n",
    "           [1.,  1.,  1.]]]], dtype=torch.float32)\n",
    "\n",
    "    # pad first so border pixels also get real derivatives\n",
    "    # pad = (left, right, top, bottom)\n",
    "    p = F.pad(paraboloid_4d, (1, 1, 1, 1), mode=\"replicate\")\n",
    "\n",
    "    gx  = F.conv2d(p, kx)\n",
    "    gy  = F.conv2d(p, ky)\n",
    "    gxx = F.conv2d(p, kxx)\n",
    "    gyy = F.conv2d(p, kyy)\n",
    "\n",
    "    return gx, gy, gxx, gyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newtonMethod(x0, y0):\n",
    "    #paraboloid = torch.tensor([constructParaboloid()]).squeeze()\n",
    "    paraboloid = torch.from_numpy(constructParaboloid()).float()\n",
    "    #paraboloid = torch.unsqueeze(paraboloid, 0)\n",
    "    paraboloid = paraboloid.unsqueeze(0).unsqueeze(0)\n",
    "    \"\"\"\n",
    "    Insert your code here\n",
    "    \"\"\"\n",
    "    gx, gy, gxx, gyy = _compute_derivatives(paraboloid)\n",
    "    H, W = paraboloid.shape[-2:] \n",
    "    # start from the given point\n",
    "    x = float(x0)\n",
    "    y = float(y0)\n",
    "\n",
    "    for _ in range(25):\n",
    "        # clamp to read derivatives\n",
    "        xi = int(round(max(0, min(W - 1, x))))\n",
    "        yi = int(round(max(0, min(H - 1, y))))\n",
    "\n",
    "        gxv  = gx[0, 0, yi, xi].item()\n",
    "        gyv  = gy[0, 0, yi, xi].item()\n",
    "        gxxv = gxx[0, 0, yi, xi].item()\n",
    "        gyyv = gyy[0, 0, yi, xi].item()\n",
    "\n",
    "        if abs(gxxv) < 1e-4: gxxv = 1e-4\n",
    "        if abs(gyyv) < 1e-4: gyyv = 1e-4\n",
    "\n",
    "        # Newton update\n",
    "        x_new = x - gxv / gxxv\n",
    "        y_new = y - gyv / gyyv\n",
    "\n",
    "        # clamp updated pos\n",
    "        x_new = max(0.0, min(W - 1.0, x_new))\n",
    "        y_new = max(0.0, min(H - 1.0, y_new))\n",
    "\n",
    "        # if Newton didn't move, take a tiny GD step\n",
    "        if abs(x_new - x) < 1e-5 and abs(y_new - y) < 1e-5:\n",
    "            gd_step = 0.2  # small nudge toward negative gradient\n",
    "            x_new = x - gd_step * gxv\n",
    "            y_new = y - gd_step * gyv\n",
    "            x_new = max(0.0, min(W - 1.0, x_new))\n",
    "            y_new = max(0.0, min(H - 1.0, y_new))\n",
    "\n",
    "        # stop if small move\n",
    "        if abs(x_new - x) < 1e-3 and abs(y_new - y) < 1e-3:\n",
    "            x, y = x_new, y_new\n",
    "            break\n",
    "\n",
    "        x, y = x_new, y_new\n",
    "\n",
    "    return int(round(x)), int(round(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x0, y0, lr=0.001):\n",
    "    #paraboloid = torch.tensor([constructParaboloid()]).squeeze()\n",
    "    paraboloid = torch.from_numpy(constructParaboloid()).float()\n",
    "    #paraboloid = torch.unsqueeze(paraboloid, 0)\n",
    "    paraboloid = paraboloid.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    \"\"\"\n",
    "    Insert your code here\n",
    "    \"\"\"\n",
    "    gx, gy, _, _ = _compute_derivatives(paraboloid)\n",
    "\n",
    "    H, W = paraboloid.shape[-2:]\n",
    "    x, y = float(x0), float(y0)\n",
    "\n",
    "    for _ in range(500):\n",
    "        xi = int(round(max(0, min(W - 1, x))))\n",
    "        yi = int(round(max(0, min(H - 1, y))))\n",
    "\n",
    "        gxv = gx[0, 0, yi, xi].item()\n",
    "        gyv = gy[0, 0, yi, xi].item()\n",
    "\n",
    "        # gradient descent step\n",
    "        x_new = x - lr * gxv\n",
    "        y_new = y - lr * gyv\n",
    "\n",
    "        x_new = max(0, min(W - 1, x_new))\n",
    "        y_new = max(0, min(H - 1, y_new))\n",
    "\n",
    "        # Stop if gradient is small\n",
    "        if (gxv ** 2 + gyv ** 2) ** 0.5 < 1e-3:\n",
    "            x, y = x_new, y_new\n",
    "            break\n",
    "        x, y = x_new, y_new\n",
    "\n",
    "    final_x, final_y = int(round(x)), int(round(y))\n",
    "\n",
    "    return final_x, final_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd(135, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m newtonMethod(\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m, in \u001b[0;36mnewtonMethod\u001b[0;34m(x0, y0)\u001b[0m\n\u001b[1;32m      5\u001b[0m paraboloid \u001b[39m=\u001b[39m paraboloid\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m gx, gy, gxx, gyy \u001b[39m=\u001b[39m _compute_derivatives(paraboloid)\n\u001b[0;32m----> 7\u001b[0m H, W \u001b[39m=\u001b[39m paraboloid[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \n\u001b[1;32m      8\u001b[0m \u001b[39m# start from the given point\u001b[39;00m\n\u001b[1;32m      9\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(x0)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "newtonMethod(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eep596-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
